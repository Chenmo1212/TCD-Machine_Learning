{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593a1dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chenmo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入所需的库\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import codecs\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90cc2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取review文件\n",
    "df = pd.read_csv('comments_transed6.csv')\n",
    "\n",
    "cache = pd.read_csv('cache.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6a77d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('comments.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4efa6e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6209"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df0['listing_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d4db73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb81e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['listing_id',\n",
       " 'id',\n",
       " 'date',\n",
       " 'reviewer_id',\n",
       " 'reviewer_name',\n",
       " 'comments',\n",
       " 'comments_trans']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'comments': 'comments_trans'})\n",
    "new_df = pd.concat([df0, df['comments_trans']], axis=1)\n",
    "new_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4ba10a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_matrix = new_df['comments_trans'].isnull()\n",
    "\n",
    "len(np.where(null_matrix == True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe2ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37afb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('comment_cleaned1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f9039",
   "metadata": {},
   "source": [
    "## 转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14b570eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取review文件\n",
    "reviews_df = pd.read_csv('comment_cleaned1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "683e0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = reviews_df['comments_trans']\n",
    "\n",
    "# remove stop words\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "tmp = tmp.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))\n",
    "\n",
    "# Segment the comments column\n",
    "reviews_df['words'] = tmp.apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(tmp)\n",
    "\n",
    "# Instantiate a CountVectorizer\n",
    "vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80507c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?', '�', '?']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m test_i \u001b[38;5;241m=\u001b[39m reviews_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m76417\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_i)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mvec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Program\\anaconda\\envs\\00_Weekly Assignments\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1338\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1330\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1332\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1333\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1334\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1335\u001b[0m             )\n\u001b[0;32m   1336\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1338\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1341\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mD:\\Program\\anaconda\\envs\\00_Weekly Assignments\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1228\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1226\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1228\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1229\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1230\u001b[0m         )\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "test_i = reviews_df['words'][76417]\n",
    "print(test_i)\n",
    "vec.fit_transform(test_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60997be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['words'][2956] = ['Image']\n",
    "\n",
    "reviews_df['words'][17800] = ['Normal']\n",
    "\n",
    "reviews_df['words'][20266] = ['prefect']\n",
    "\n",
    "reviews_df['words'][24477] = ['normal']\n",
    "\n",
    "reviews_df['words'][30336] = ['bad']\n",
    "\n",
    "reviews_df['words'][32539] = ['normal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c626fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = reviews_df['listing_id']\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab510f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = ['C']\n",
    "\n",
    "print(len(it) == 1)\n",
    "\n",
    "if len(it) == 1 and len(it[0]) == 1 or len(it) == 0:\n",
    "    print('111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ccc4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 用词袋模型将分词后的文本转换成文本向量\n",
    "# reviews_df['vector'] = reviews_df['words'].apply(lambda x: vec.fit_transform(x).toarray())\n",
    "\n",
    "temp = []\n",
    "for i in range(len(reviews_df['words'])):\n",
    "    item = reviews_df['words'][i]\n",
    "\n",
    "    print(i, item)\n",
    "\n",
    "    if len(item) == 1 and len(item[0]) == 1 or len(item) == 0:\n",
    "        reviews_df['words'][i] = ['normal']\n",
    "\n",
    "    res = vec.fit_transform(reviews_df['words'][i]).toarray()\n",
    "    temp.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eefb721",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['vector'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6033c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_csv('comment_cleaned_vec.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba479ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(['D222'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e901fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据listing_id计算文本向量的平均值\n",
    "# data_mean = reviews_df.groupby('listing_id')['vector'].mean()\n",
    "\n",
    "df_mean = pd.DataFrame(columns=['listing_id','data_mean'])\n",
    "listing_ids = reviews_df['listing_id'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09823e47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m list_means \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vector \u001b[38;5;129;01min\u001b[39;00m vectors:\n\u001b[1;32m----> 6\u001b[0m     list_means\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#计算整个列表的均值\u001b[39;00m\n\u001b[0;32m      9\u001b[0m final_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(list_means)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mD:\\Program\\anaconda\\envs\\00_Weekly Assignments\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3437\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3438\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3441\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Program\\anaconda\\envs\\00_Weekly Assignments\\lib\\site-packages\\numpy\\core\\_methods.py:179\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    176\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    177\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    181\u001b[0m     ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(\n\u001b[0;32m    182\u001b[0m             ret, rcount, out\u001b[38;5;241m=\u001b[39mret, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "for listing_id in listing_ids:\n",
    "    vectors = reviews_df[reviews_df['listing_id']==listing_id]['vector']\n",
    "\n",
    "    list_means = []\n",
    "    for vector in vectors:\n",
    "        list_means.append(np.mean(vector))\n",
    "\n",
    "    #计算整个列表的均值\n",
    "    final_mean = np.mean(list_means)\n",
    "    \n",
    "    df_mean = df_mean.append({'listing_id':listing_id,'data_mean':final_mean}, ignore_index=True)\n",
    "\n",
    "df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82205e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将每个listing_id的vector均值添加到原来的df中\n",
    "reviews_df = reviews_df.merge(df_mean, on='listing_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf081b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_csv('comment_cleaned_vec.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c97e8",
   "metadata": {},
   "source": [
    "## 合并listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "347ed229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取listing文件\n",
    "listing_df = pd.read_csv('cleaned_data.csv')\n",
    "reviews_df = pd.read_csv('comment_cleaned_vec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54d2cb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7566, 45)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03edab24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234365, 10)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f4337de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['listing_id',\n",
       " 'id',\n",
       " 'date',\n",
       " 'reviewer_id',\n",
       " 'reviewer_name',\n",
       " 'comments',\n",
       " 'comments_trans',\n",
       " 'words',\n",
       " 'vector',\n",
       " 'data_mean']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4850ab0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234365, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean_df = reviews_df[['listing_id', 'data_mean']].copy()\n",
    "data_mean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a306ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean_df.rename(columns={'listing_id': 'id'}, inplace=True)\n",
    "data_mean_df.rename(columns={'data_mean': 'review_mean'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8cdd035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5185"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_mean_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f0a39a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44077</td>\n",
       "      <td>0.061733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>302634</td>\n",
       "      <td>0.067611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1797712</td>\n",
       "      <td>0.039422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>374792</td>\n",
       "      <td>0.064033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>386860</td>\n",
       "      <td>0.059420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  review_mean\n",
       "0      44077     0.061733\n",
       "256   302634     0.067611\n",
       "360  1797712     0.039422\n",
       "427   374792     0.064033\n",
       "462   386860     0.059420"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "928e8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean_df.drop_duplicates(subset=None, keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ff0d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_df = listing_df.merge(data_mean_df, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f780afca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>...</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>host_days_active</th>\n",
       "      <th>verification_count</th>\n",
       "      <th>property_type_category</th>\n",
       "      <th>bathrooms_type</th>\n",
       "      <th>amenities_count</th>\n",
       "      <th>review_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>44077</td>\n",
       "      <td>2010-08-06</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4419.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>994</td>\n",
       "      <td>0.061733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85156</td>\n",
       "      <td>2010-08-06</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4419.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>657</td>\n",
       "      <td>0.066811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>159889</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.78</td>\n",
       "      <td>4090.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>491</td>\n",
       "      <td>0.086331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>162809</td>\n",
       "      <td>2011-07-04</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.68</td>\n",
       "      <td>4087.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>892</td>\n",
       "      <td>0.088974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>165828</td>\n",
       "      <td>2011-07-07</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>4084.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>482</td>\n",
       "      <td>0.079291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id  host_since  host_response_time  host_response_rate  \\\n",
       "0           0   44077  2010-08-06                   4                   1   \n",
       "1           1   85156  2010-08-06                   4                   1   \n",
       "2           2  159889  2011-07-01                   4                   1   \n",
       "3           3  162809  2011-07-04                   4                   3   \n",
       "4           4  165828  2011-07-07                   4                   1   \n",
       "\n",
       "   host_acceptance_rate  host_is_superhost  host_verifications  \\\n",
       "0                     3                  1                   1   \n",
       "1                     3                  1                   1   \n",
       "2                     3                  0                   1   \n",
       "3                     2                  1                   1   \n",
       "4                     3                  0                   1   \n",
       "\n",
       "   host_has_profile_pic  host_identity_verified  ...  \\\n",
       "0                     1                       1  ...   \n",
       "1                     1                       1  ...   \n",
       "2                     1                       1  ...   \n",
       "3                     1                       1  ...   \n",
       "4                     1                       1  ...   \n",
       "\n",
       "   calculated_host_listings_count_entire_homes  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          5.0   \n",
       "\n",
       "   calculated_host_listings_count_private_rooms  \\\n",
       "0                                           2.0   \n",
       "1                                           2.0   \n",
       "2                                           3.0   \n",
       "3                                           2.0   \n",
       "4                                           0.0   \n",
       "\n",
       "   calculated_host_listings_count_shared_rooms  reviews_per_month  \\\n",
       "0                                          0.0               1.85   \n",
       "1                                          0.0               1.53   \n",
       "2                                          0.0               2.78   \n",
       "3                                          0.0               3.68   \n",
       "4                                          0.0               0.48   \n",
       "\n",
       "   host_days_active  verification_count  property_type_category  \\\n",
       "0            4419.0                   2                       2   \n",
       "1            4419.0                   2                       2   \n",
       "2            4090.0                   2                       3   \n",
       "3            4087.0                   2                       3   \n",
       "4            4084.0                   2                       0   \n",
       "\n",
       "   bathrooms_type  amenities_count  review_mean  \n",
       "0               6              994     0.061733  \n",
       "1               6              657     0.066811  \n",
       "2               8              491     0.086331  \n",
       "3               6              892     0.088974  \n",
       "4               3              482     0.079291  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4ebd283c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5185, 46)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "70375248",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "listing_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "391a7223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'host_since',\n",
       " 'host_response_time',\n",
       " 'host_response_rate',\n",
       " 'host_acceptance_rate',\n",
       " 'host_is_superhost',\n",
       " 'host_verifications',\n",
       " 'host_has_profile_pic',\n",
       " 'host_identity_verified',\n",
       " 'neighbourhood_cleansed',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'accommodates',\n",
       " 'bathrooms_text',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'amenities',\n",
       " 'price',\n",
       " 'minimum_nights',\n",
       " 'maximum_nights',\n",
       " 'number_of_reviews',\n",
       " 'number_of_reviews_ltm',\n",
       " 'number_of_reviews_l30d',\n",
       " 'first_review',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'instant_bookable',\n",
       " 'calculated_host_listings_count',\n",
       " 'calculated_host_listings_count_entire_homes',\n",
       " 'calculated_host_listings_count_private_rooms',\n",
       " 'calculated_host_listings_count_shared_rooms',\n",
       " 'reviews_per_month',\n",
       " 'host_days_active',\n",
       " 'verification_count',\n",
       " 'property_type_category',\n",
       " 'bathrooms_type',\n",
       " 'amenities_count',\n",
       " 'review_mean']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a5d7b098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_df['review_mean'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "96d606d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_df.to_csv('cleaned_data_review.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (machine_learning)",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
